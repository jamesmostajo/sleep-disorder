{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>70.09</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>94.39</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80.43</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120.46</td>\n",
       "      <td>36.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>104.51</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0  1.0  63.0             0              1             1          4   \n",
       "1  1.0  42.0             0              1             1          4   \n",
       "2  0.0  61.0             0              0             1          4   \n",
       "3  1.0  41.0             1              0             1          3   \n",
       "4  1.0  85.0             0              0             1          4   \n",
       "5  1.0  55.0             1              1             1          4   \n",
       "6  0.0  82.0             0              0             0          4   \n",
       "7  0.0  17.0             1              0             1          4   \n",
       "8  1.0  31.0             0              1             1          2   \n",
       "9  0.0  55.0             0              0             1          4   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               1             228.69  36.6               1       1  \n",
       "1               0             105.92  32.5               0       1  \n",
       "2               1             171.23  34.4               1       1  \n",
       "3               0             174.12  24.0               0       1  \n",
       "4               1             186.21  29.0               1       1  \n",
       "5               0              70.09  27.4               0       1  \n",
       "6               1              94.39  22.8               0       1  \n",
       "7               0              80.43  29.7               0       1  \n",
       "8               0             120.46  36.8               1       1  \n",
       "9               1             104.51  27.3               1       1  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('stroke_data.csv').dropna()\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      4117\n",
      "           1       0.90      0.92      0.91      4065\n",
      "\n",
      "    accuracy                           0.91      8182\n",
      "   macro avg       0.91      0.91      0.91      8182\n",
      "weighted avg       0.91      0.91      0.91      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "X = df.drop(columns=[\"stroke\"])\n",
    "y = df[\"stroke\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "scalers = {}\n",
    "for col in X_train.columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train[col] = scaler.fit_transform(X_train[col].values.reshape(-1, 1))\n",
    "    scalers[col] = scaler\n",
    "\n",
    "for col in X_test.columns:\n",
    "    X_test[col] = scalers[col].transform(X_test[col].values.reshape(-1, 1))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "knn = model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4117\n",
      "           1       1.00      1.00      1.00      4065\n",
      "\n",
      "    accuracy                           1.00      8182\n",
      "   macro avg       1.00      1.00      1.00      8182\n",
      "weighted avg       1.00      1.00      1.00      8182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "decisiontree = model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['stroke'])\n",
    "y = df[['stroke']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(X_train.values, dtype=torch.float32), torch.tensor(y_train.values, dtype=torch.float32))\n",
    "test_ds = TensorDataset(torch.tensor(X_test.values, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=20, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TunableModel(nn.Module):\n",
    "    def __init__(self, num_hidden_nodes, num_hidden_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # add Input Layer\n",
    "        self.input_layer = nn.Linear(10, num_hidden_nodes)\n",
    "\n",
    "        # Add a Mechanism that would add n number of hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(num_hidden_layers):\n",
    "            hidden_layers.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
    "            hidden_layers.append(nn.ReLU())\n",
    "        \n",
    "        # Add a Sequential Portion to house all hidden layers\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        # Add Output Layer\n",
    "        self.output_layer = nn.Linear(num_hidden_nodes, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        pred = self.sigmoid(x)\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "# Training Steps\n",
    "def train(model, dataloader, epochs, loss_fn, optimizer, verbose=True):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "        for X_val, y_val in dataloader:\n",
    "            pred = model(X_val)\n",
    "            loss = loss_fn(pred, y_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            # Print Tracker only every 100 steps\n",
    "            if i % 100 == 0 and verbose:\n",
    "                print('Epoch {0} Step {1}: Loss - {2}'.format(epoch+1, i, loss.item()), end='\\r')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    # Make Predictions\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in dataloader:\n",
    "            pred = model(X_val).round()\n",
    "            preds.extend(pred.numpy())\n",
    "            trues.extend(y_val.numpy())\n",
    "    \n",
    "    return f1_score(trues, preds)\n",
    "\n",
    "\n",
    "# Define our optimization loop\n",
    "\n",
    "def score_hyperparameter_sets(hyperparameter_sets):\n",
    "    scores = []\n",
    "    models = []\n",
    "\n",
    "    # Iterate through the entire set to get scores\n",
    "    for hyperparameter_set in hyperparameter_sets:\n",
    "        # Set Random State for Reproducibility\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # Unpack all hyperparameters in the set\n",
    "        hidden_nodes = hyperparameter_set['hidden_nodes']\n",
    "        hidden_layers = hyperparameter_set['hidden_layers']\n",
    "        # Define the Model with hyperparameters\n",
    "        model = TunableModel(num_hidden_nodes=hidden_nodes, num_hidden_layers=hidden_layers)\n",
    "\n",
    "        # Define Training Objects\n",
    "        loss_fn = nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train Model\n",
    "        print(f'Training Model with HP: (Hidden Nodes-{hidden_nodes}, Hidden Layers-{hidden_layers})')\n",
    "        model = train(model, train_dl, 10, loss_fn, optimizer)\n",
    "\n",
    "        # Test Model\n",
    "        score = test(model, test_dl)\n",
    "\n",
    "        scores.append(score)\n",
    "        models.append(model)\n",
    "\n",
    "\n",
    "    # Make Table to show the results\n",
    "    results = pd.DataFrame(hyperparameter_sets)\n",
    "    results['score'] = scores\n",
    "    results['model'] = models\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_nodes': range(20, 201, 20), 'hidden_layers': range(0, 5)}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_space = {\n",
    "    'hidden_nodes': range(10, 200+1, 10),\n",
    "    'hidden_layers': range(0, 5, 1)\n",
    "}\n",
    "hyperparameter_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hidden_nodes': 20, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 20, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 20, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 20, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 20, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 40, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 40, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 40, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 40, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 40, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 60, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 60, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 60, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 60, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 60, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 80, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 80, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 80, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 80, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 80, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 100, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 100, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 100, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 100, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 100, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 120, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 120, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 120, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 120, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 120, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 140, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 140, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 140, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 140, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 140, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 160, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 160, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 160, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 160, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 160, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 180, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 180, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 180, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 180, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 180, 'hidden_layers': 4},\n",
       " {'hidden_nodes': 200, 'hidden_layers': 0},\n",
       " {'hidden_nodes': 200, 'hidden_layers': 1},\n",
       " {'hidden_nodes': 200, 'hidden_layers': 2},\n",
       " {'hidden_nodes': 200, 'hidden_layers': 3},\n",
       " {'hidden_nodes': 200, 'hidden_layers': 4}]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_hp_space_to_sets(hpo_space):\n",
    "    hp_sets = []\n",
    "    for hidden_nodes in hpo_space['hidden_nodes']:\n",
    "        for hidden_layers in hpo_space['hidden_layers']:\n",
    "            hp_sets.append({'hidden_nodes': hidden_nodes, 'hidden_layers': hidden_layers})\n",
    "    \n",
    "    return hp_sets\n",
    "\n",
    "hp_sets = convert_hp_space_to_sets(hyperparameter_space)\n",
    "hp_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with HP: (Hidden Nodes-20, Hidden Layers-0)\n",
      "Epoch 1 Step 1000: Loss - 0.7077620625495911\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[285], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mscore_hyperparameter_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp_sets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sorted_models \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[282], line 64\u001b[0m, in \u001b[0;36mscore_hyperparameter_sets\u001b[0;34m(hyperparameter_sets)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Model with HP: (Hidden Nodes-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Hidden Layers-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Test Model\u001b[39;00m\n\u001b[1;32m     67\u001b[0m score \u001b[38;5;241m=\u001b[39m test(model, test_dl)\n",
      "Cell \u001b[0;32mIn[282], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, epochs, loss_fn, optimizer, verbose)\u001b[0m\n\u001b[1;32m      7\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_val, y_val \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m----> 9\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y_val)\n\u001b[1;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/CSCI114/virtualenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CSCI114/virtualenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[281], line 25\u001b[0m, in \u001b[0;36mTunableModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers(x)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x)\n\u001b[0;32m---> 25\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/Documents/CSCI114/virtualenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CSCI114/virtualenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CSCI114/virtualenv/lib/python3.9/site-packages/torch/nn/modules/activation.py:301\u001b[0m, in \u001b[0;36mSigmoid.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_df = score_hyperparameter_sets(hp_sets)\n",
    "sorted_models = results_df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_nodes</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.671525</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666175</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663836</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.662044</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0.653673</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.651799</td>\n",
       "      <td>TunableModel(\\n  (input_layer): Linear(in_feat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_nodes  hidden_layers     score  \\\n",
       "47           200              2  0.671525   \n",
       "15            80              0  0.666175   \n",
       "30           140              0  0.663836   \n",
       "35           160              0  0.663836   \n",
       "45           200              0  0.663836   \n",
       "40           180              0  0.663836   \n",
       "25           120              0  0.663836   \n",
       "26           120              1  0.662044   \n",
       "36           160              1  0.653673   \n",
       "10            60              0  0.651799   \n",
       "\n",
       "                                                model  \n",
       "47  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "15  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "30  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "35  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "45  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "40  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "25  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "26  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "36  TunableModel(\\n  (input_layer): Linear(in_feat...  \n",
       "10  TunableModel(\\n  (input_layer): Linear(in_feat...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_models[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn, 'knn.pkl')\n",
    "joblib.dump(decisiontree, 'knn.pkl')\n",
    "torch.save(sorted_models.iloc[0]['model'].state_dict(), 'neural-network.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
